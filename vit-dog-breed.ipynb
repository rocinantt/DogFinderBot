{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":791828,"sourceType":"datasetVersion","datasetId":119698},{"sourceId":9179689,"sourceType":"datasetVersion","datasetId":5548216}],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## Библиотеки","metadata":{}},{"cell_type":"code","source":"!pip install evaluate -q","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:26:18.388910Z","iopub.execute_input":"2024-08-15T15:26:18.389337Z","iopub.status.idle":"2024-08-15T15:26:35.584148Z","shell.execute_reply.started":"2024-08-15T15:26:18.389305Z","shell.execute_reply":"2024-08-15T15:26:35.582592Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport random\nimport datasets\nimport cv2\nimport json\nimport pandas as pd\nfrom pathlib import Path\nfrom collections import defaultdict\nfrom PIL import Image\n\nimport torch\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import top_k_accuracy_score\n\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\n\nfrom transformers.trainer_callback import EarlyStoppingCallback\nfrom transformers import ViTImageProcessor, ViTForImageClassification, TrainingArguments, Trainer\nfrom datasets import Dataset as HFDataset, DatasetDict, load_dataset\nfrom tqdm import tqdm\nimport evaluate\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:28:36.471391Z","iopub.execute_input":"2024-08-15T15:28:36.471810Z","iopub.status.idle":"2024-08-15T15:28:36.481120Z","shell.execute_reply.started":"2024-08-15T15:28:36.471776Z","shell.execute_reply":"2024-08-15T15:28:36.479726Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"SEED = 42\nrandom.seed(SEED)\ntorch.manual_seed(SEED)\nnp.random.seed(SEED)\n\ndata_dir = '/kaggle/input/stanford-dogs-dataset/images/Images'","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:26:58.950769Z","iopub.execute_input":"2024-08-15T15:26:58.952230Z","iopub.status.idle":"2024-08-15T15:26:58.960776Z","shell.execute_reply.started":"2024-08-15T15:26:58.952186Z","shell.execute_reply":"2024-08-15T15:26:58.959771Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"## Препроцессинг","metadata":{}},{"cell_type":"code","source":"# Создание словарей для сопоставления ID и меток\nID2LABEL = {}\nLABEL2ID = {}\nfor idx, image_filename in enumerate(os.listdir(data_dir)):\n    if not image_filename.endswith('.xlsx'):\n        label = image_filename.split('-')[1].lower()\n        ID2LABEL[idx] = label\n        LABEL2ID[label] = idx\nNUM_LABELS = len(ID2LABEL)\nprint(f\"NUM_LABELS: {NUM_LABELS}\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:26:58.963360Z","iopub.execute_input":"2024-08-15T15:26:58.963722Z","iopub.status.idle":"2024-08-15T15:26:58.994730Z","shell.execute_reply.started":"2024-08-15T15:26:58.963681Z","shell.execute_reply":"2024-08-15T15:26:58.993582Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"NUM_LABELS: 120\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# Функция для загрузки изображений и меток\ndef load_images(data_dir):\n    categories = os.listdir(data_dir)\n    images = []\n    labels = []\n\n    for category in tqdm(categories):\n        category_path = os.path.join(data_dir, category)\n        all_images = os.listdir(category_path)\n\n        for image_name in all_images:\n            image_path = os.path.join(category_path, image_name)\n            label = category.split('-')[1].lower()\n\n            images.append(image_path)\n            labels.append(label)\n\n    return images, labels","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:26:58.996052Z","iopub.execute_input":"2024-08-15T15:26:58.996483Z","iopub.status.idle":"2024-08-15T15:26:59.004589Z","shell.execute_reply.started":"2024-08-15T15:26:58.996445Z","shell.execute_reply":"2024-08-15T15:26:59.003347Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"# Загрузка путей к изображениям и меток\nimages, labels = load_images(data_dir)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:26:59.006389Z","iopub.execute_input":"2024-08-15T15:26:59.007107Z","iopub.status.idle":"2024-08-15T15:27:01.853368Z","shell.execute_reply.started":"2024-08-15T15:26:59.007066Z","shell.execute_reply":"2024-08-15T15:27:01.852205Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"100%|██████████| 120/120 [00:02<00:00, 42.45it/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"train_paths, val_paths, train_labels, val_labels = train_test_split(\n    images, \n    labels, \n    test_size=0.2, \n    random_state=SEED, \n    stratify=labels\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:27:01.855236Z","iopub.execute_input":"2024-08-15T15:27:01.855607Z","iopub.status.idle":"2024-08-15T15:27:01.902604Z","shell.execute_reply.started":"2024-08-15T15:27:01.855578Z","shell.execute_reply":"2024-08-15T15:27:01.901408Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"# Создание объекта Dataset\ntrain_dataset = datasets.Dataset.from_dict(\n    mapping = {'image': train_paths, 'labels': train_labels,},\n    features = datasets.Features({\n        'image': datasets.Image(),\n        'labels': datasets.features.ClassLabel(names=list(LABEL2ID.keys())),\n    })\n)\n# Создание объекта Dataset\nval_dataset = datasets.Dataset.from_dict(\n    mapping = {'image': val_paths, 'labels': val_labels,},\n    features = datasets.Features({\n        'image': datasets.Image(),\n        'labels': datasets.features.ClassLabel(names=list(LABEL2ID.keys())),\n    })\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:27:01.904121Z","iopub.execute_input":"2024-08-15T15:27:01.904508Z","iopub.status.idle":"2024-08-15T15:27:02.176984Z","shell.execute_reply.started":"2024-08-15T15:27:01.904478Z","shell.execute_reply":"2024-08-15T15:27:02.175988Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Инициализация процессора изображений\nprocessor = ViTImageProcessor.from_pretrained(\"google/vit-large-patch32-384\")\n# Загрузка модели ViT для классификации изображений\nmodel = ViTForImageClassification.from_pretrained(\n    'google/vit-large-patch32-384',\n    num_labels=len(LABEL2ID),\n    id2label=ID2LABEL,\n    label2id=LABEL2ID,\n    ignore_mismatched_sizes=True\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:27:02.178425Z","iopub.execute_input":"2024-08-15T15:27:02.178856Z","iopub.status.idle":"2024-08-15T15:27:14.951614Z","shell.execute_reply.started":"2024-08-15T15:27:02.178818Z","shell.execute_reply":"2024-08-15T15:27:14.950187Z"},"trusted":true},"execution_count":10,"outputs":[{"output_type":"display_data","data":{"text/plain":"preprocessor_config.json:   0%|          | 0.00/160 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6969ec32cc043de9a324bb5fe39940f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/69.7k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"564c04a0488044c88be8d221fe62db0b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/1.23G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3613d057907b41e39fa0d6ad89fe1e8d"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n  return self.fget.__get__(instance, owner)()\nSome weights of ViTForImageClassification were not initialized from the model checkpoint at google/vit-large-patch32-384 and are newly initialized because the shapes did not match:\n- classifier.weight: found shape torch.Size([1000, 1024]) in the checkpoint and torch.Size([120, 1024]) in the model instantiated\n- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([120]) in the model instantiated\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"def train_transforms(example):\n    # Применение процессора ко всем изображениям в примере\n    images = [image.convert('RGB') for image in example['image']]\n    example.update(processor(images, return_tensors='pt'))\n    return example\n\ndef eval_transforms(example):\n    # Применение процессора ко всем изображениям в примере\n    images = [image.convert('RGB') for image in example['image']]\n    example.update(processor(images, return_tensors='pt'))\n    return example","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:27:14.956776Z","iopub.execute_input":"2024-08-15T15:27:14.957214Z","iopub.status.idle":"2024-08-15T15:27:14.967379Z","shell.execute_reply.started":"2024-08-15T15:27:14.957182Z","shell.execute_reply":"2024-08-15T15:27:14.966316Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"# Применение трансформаций к данным\ntrain_dataset.set_transform(train_transforms)\nval_dataset.set_transform(eval_transforms)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:27:14.968771Z","iopub.execute_input":"2024-08-15T15:27:14.969218Z","iopub.status.idle":"2024-08-15T15:27:16.443896Z","shell.execute_reply.started":"2024-08-15T15:27:14.969186Z","shell.execute_reply":"2024-08-15T15:27:16.442369Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"markdown","source":"## Обучение","metadata":{}},{"cell_type":"code","source":"# Инициализация метрик для оценки\naccuracy_metric = evaluate.load('accuracy')\nf1_metric = evaluate.load('f1')","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:27:16.448737Z","iopub.execute_input":"2024-08-15T15:27:16.449112Z","iopub.status.idle":"2024-08-15T15:27:17.396157Z","shell.execute_reply.started":"2024-08-15T15:27:16.449082Z","shell.execute_reply":"2024-08-15T15:27:17.395096Z"},"trusted":true},"execution_count":13,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/4.20k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a650201343647e988efd5c040da2e1c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/6.77k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"264d6a705efa4f6fb163d599cd5e3067"}},"metadata":{}}]},{"cell_type":"code","source":"# Функция для вычисления метрик\ndef compute_metrics(eval_pred):\n    logits, labels = eval_pred\n    preds = np.argmax(logits, axis=-1)\n    accuracy = accuracy_metric.compute(predictions=preds, references=labels)\n    top3_accuracy = top_k_accuracy_score(labels, logits, k=3)\n    top5_accuracy = top_k_accuracy_score(labels, logits, k=5)\n    f1 = f1_metric.compute(predictions=preds, references=labels, average='macro')\n    \n    return {\n        **accuracy,\n        'top3_accuracy': top3_accuracy,\n        'top5_accuracy': top5_accuracy,\n        **f1,\n    }","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:27:17.398069Z","iopub.execute_input":"2024-08-15T15:27:17.398532Z","iopub.status.idle":"2024-08-15T15:27:17.406898Z","shell.execute_reply.started":"2024-08-15T15:27:17.398492Z","shell.execute_reply":"2024-08-15T15:27:17.405854Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"# Функция для объединения данных в батчи\ndef collate_fn(batch):\n    return {\n        'pixel_values': torch.stack([x['pixel_values'] for x in batch]),\n        'labels': torch.tensor([x['labels'] for x in batch])\n    }","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:27:17.408043Z","iopub.execute_input":"2024-08-15T15:27:17.408467Z","iopub.status.idle":"2024-08-15T15:27:17.883636Z","shell.execute_reply.started":"2024-08-15T15:27:17.408432Z","shell.execute_reply":"2024-08-15T15:27:17.882390Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Аргументы для тренировки модели\ntraining_args = TrainingArguments(\n    seed=SEED,\n    output_dir='./results',\n    optim='adamw_torch',\n    num_train_epochs=30,\n    gradient_accumulation_steps=4,\n    per_device_train_batch_size=16,\n    per_device_eval_batch_size=64,\n    save_strategy='epoch',\n    eval_strategy='epoch',\n    load_best_model_at_end=True,\n    save_total_limit=2,\n    report_to='wandb',\n    learning_rate=1e-5,\n    remove_unused_columns=False,\n    metric_for_best_model='accuracy',\n    fp16=True,\n    lr_scheduler_type='cosine',  # Косинусное уменьшение lr\n    warmup_ratio=0.1,  # Warmup для lr\n    dataloader_pin_memory=True,\n\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:27:17.885249Z","iopub.execute_input":"2024-08-15T15:27:17.885673Z","iopub.status.idle":"2024-08-15T15:27:17.905554Z","shell.execute_reply.started":"2024-08-15T15:27:17.885632Z","shell.execute_reply":"2024-08-15T15:27:17.904327Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Инициализация объекта Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    data_collator=collate_fn,\n    tokenizer=processor,\n    compute_metrics=compute_metrics,\n    callbacks=[EarlyStoppingCallback(early_stopping_patience=5)]\n)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:27:17.906973Z","iopub.execute_input":"2024-08-15T15:27:17.907714Z","iopub.status.idle":"2024-08-15T15:27:19.927819Z","shell.execute_reply.started":"2024-08-15T15:27:17.907673Z","shell.execute_reply":"2024-08-15T15:27:19.926222Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":17,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[17], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Инициализация объекта Trainer\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[43mTrainer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraining_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_collator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprocessor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompute_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mEarlyStoppingCallback\u001b[49m\u001b[43m(\u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:639\u001b[0m, in \u001b[0;36mTrainer.__init__\u001b[0;34m(self, model, args, data_collator, train_dataset, eval_dataset, tokenizer, model_init, compute_metrics, callbacks, optimizers, preprocess_logits_for_metrics)\u001b[0m\n\u001b[1;32m    637\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m args\u001b[38;5;241m.\u001b[39mfp16:\n\u001b[1;32m    638\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_greater_or_equal_than_2_3:\n\u001b[0;32m--> 639\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTried to use `fp16` but it is not supported on cpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    640\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    641\u001b[0m     args\u001b[38;5;241m.\u001b[39mhalf_precision_backend \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu_amp\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","\u001b[0;31mValueError\u001b[0m: Tried to use `fp16` but it is not supported on cpu"],"ename":"ValueError","evalue":"Tried to use `fp16` but it is not supported on cpu","output_type":"error"}]},{"cell_type":"code","source":"#trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:28:22.513805Z","iopub.execute_input":"2024-08-15T15:28:22.514287Z","iopub.status.idle":"2024-08-15T15:28:22.519030Z","shell.execute_reply.started":"2024-08-15T15:28:22.514253Z","shell.execute_reply":"2024-08-15T15:28:22.517928Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"with open(\"/kaggle/input/training-state/trainer_state.json\", \"r\") as file:\n    trainer_state = json.load(file)\n\n# Извлечение истории метрик\nhistory = trainer_state['log_history']\n\n# Инициализация списка для хранения данных\ndata = []\n\n# Проход по всей истории и сбор метрик для каждой эпохи\nfor entry in history:\n    row = {\n        \"Validation Loss\": entry.get('eval_loss', None),\n        \"Validation Accuracy\": entry.get('eval_accuracy', None),\n        \"Validation F1 Score\": entry.get('eval_f1', None),\n        \"Validation Top-3 Accuracy\": entry.get('eval_top3_accuracy', None),\n        \"Validation Top-5 Accuracy\": entry.get('eval_top5_accuracy', None)\n    }\n    data.append(row)\n\n# Создание DataFrame из списка\ndf_metrics = pd.DataFrame(data)\n\n# Фильтрация столбцов для вывода только необходимых метрик\ndf_metrics_filtered = df_metrics[[\n    \"Validation Loss\", \n    \"Validation Accuracy\", \n    \"Validation Top-3 Accuracy\", \n    \"Validation Top-5 Accuracy\", \n    \"Validation F1 Score\"\n]]\ndf_metrics_filtered = df_metrics_filtered.dropna(subset=['Validation Loss'], axis=0).reset_index(drop=True)","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:38:59.056101Z","iopub.execute_input":"2024-08-15T15:38:59.056544Z","iopub.status.idle":"2024-08-15T15:38:59.088284Z","shell.execute_reply.started":"2024-08-15T15:38:59.056514Z","shell.execute_reply":"2024-08-15T15:38:59.087085Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":59,"outputs":[]},{"cell_type":"code","source":"df_metrics_filtered","metadata":{"execution":{"iopub.status.busy":"2024-08-15T15:38:34.088819Z","iopub.execute_input":"2024-08-15T15:38:34.089545Z","iopub.status.idle":"2024-08-15T15:38:34.113641Z","shell.execute_reply.started":"2024-08-15T15:38:34.089499Z","shell.execute_reply":"2024-08-15T15:38:34.112532Z"},"trusted":true},"execution_count":58,"outputs":[{"execution_count":58,"output_type":"execute_result","data":{"text/plain":"   Validation Loss  Validation Accuracy  Validation Top-3 Accuracy  \\\n0         4.544873             0.030612                   0.081390   \n1         3.117323             0.661808                   0.851069   \n2         1.238540             0.872935                   0.972546   \n3         0.567880             0.908163                   0.982750   \n4         0.406856             0.910107                   0.982507   \n5         0.360546             0.910836                   0.981293   \n6         0.348630             0.914966                   0.981050   \n\n   Validation Top-5 Accuracy  Validation F1 Score  \n0                   0.125850             0.022641  \n1                   0.906463             0.628339  \n2                   0.983965             0.866364  \n3                   0.989310             0.905838  \n4                   0.989796             0.907745  \n5                   0.989067             0.907947  \n6                   0.988338             0.911770  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Validation Loss</th>\n      <th>Validation Accuracy</th>\n      <th>Validation Top-3 Accuracy</th>\n      <th>Validation Top-5 Accuracy</th>\n      <th>Validation F1 Score</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>4.544873</td>\n      <td>0.030612</td>\n      <td>0.081390</td>\n      <td>0.125850</td>\n      <td>0.022641</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>3.117323</td>\n      <td>0.661808</td>\n      <td>0.851069</td>\n      <td>0.906463</td>\n      <td>0.628339</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1.238540</td>\n      <td>0.872935</td>\n      <td>0.972546</td>\n      <td>0.983965</td>\n      <td>0.866364</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0.567880</td>\n      <td>0.908163</td>\n      <td>0.982750</td>\n      <td>0.989310</td>\n      <td>0.905838</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0.406856</td>\n      <td>0.910107</td>\n      <td>0.982507</td>\n      <td>0.989796</td>\n      <td>0.907745</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>0.360546</td>\n      <td>0.910836</td>\n      <td>0.981293</td>\n      <td>0.989067</td>\n      <td>0.907947</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>0.348630</td>\n      <td>0.914966</td>\n      <td>0.981050</td>\n      <td>0.988338</td>\n      <td>0.911770</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}